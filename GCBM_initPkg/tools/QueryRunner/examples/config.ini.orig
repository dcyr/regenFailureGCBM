[DEFAULT]
###
# The DEFAULT section contains configuration items that affect the behaviour
# of the script globally. Global configuration can be referenced from anywhere
# in the configuration file by using the '$' character and the name of the
# configuration item, i.e. $output_path.
#
# Configuration options:
#
#     output_path
#         Full path to the root directory to store script output in. Often the
#         script output will be organized into subdirectories, but output_path
#         represents the top-level directory in the hierarchy, i.e.
#             c:\script_output
#
#     log_path
#         Full path to the directory to store log files in, i.e.
#             $output_path\Logs
#         ALL logs in log_path will be deleted when the script runs.
#
#     log_queries
#         [True/False]
#         Flag to turn on or off the logging of all SQL executed by the script.
#         Logs will be placed in log_path.
#
#     overwrite_working_dbs
#         [True/False]
#         Flag indicating whether or not to delete existing working databases
#         specified by working_db_path in the [databases] configuration section.
#         If False, existing databases will be kept, but individual tables may
#         be replaced at the discretion of each task module.
#
#     overwrite_reporting_tables
#         [True/False]
#         Flag indicating whether or not to drop existing reporting tables
#         specified by queries which make use of the reporting feature. If
#         False, reporting data will be appended to the existing tables.
#
#     logging_config
#         Absolute or relative path from this config file to the QueryRunner
#         logging config file.
###
output_path                = C:\QueryRunner
log_path                   = $output_path\Logs
log_queries                = True
overwrite_working_dbs      = True
overwrite_reporting_tables = True
logging_config             = ..\conf\logging.ini

[databases]
###
# This section contains the databases to run each query or data import against.
# Entries can be added or removed freely.
#
# Configuration options:
#
#     enabled
#         [True/False]
#         Flag indicating whether this database should be processed or not.
#
#     original_db_path
#         Path to the original database. This is treated as read-only by the
#         script.
#
#     working_db_path
#         Path to the project's working database. If it does not exist, or if
#         the overwrite_working_dbs flag is set, it will be created by copying
#         the database specified in input_db_path.
###
    [[Alberta_half]]
    enabled          = True
    original_db_path = ..\examples\AB_half_NIR2012.mdb
    working_db_path  = $output_path\AB_half_NIR2012.mdb

[data_imports]
###
# This section allows you to import data from external sources into each
# configured database. By default, the new table is named according to the
# data import (the name enclosed in the [[subsection header]]).
#
# Configuration options:
#
#     order
#         The order that a data import task runs in.
#
#     file
#         Absolute or relative path to a file to import data from.
#
#     type (optional)
#         Specifies the type of the file. If this parameter is not provided,
#         QueryRunner will use the file extension.
#         Valid types:
#             xls - Excel (2003 or 2010/xlsx)
#             csv - Delimited text
#             mdb - MS Access (2003 or 2010/accdb)
#
#     table (mdb only)
#         Specifies the table to import, if importing from an MS Access database
#         (.mdb or .accdb).
#
#     columns (optional - csv/xls only)
#         Specifies the column names to use in the output table. If this
#         parameter is not provided, the column names are taken from the first
#         row in the range.
#
#     worksheet (xls only)
#         Specifies the worksheet to import data from.
#
#     start_cell (xls only)
#         Specifies the top-left cell in the range of data to import.
#
#     end_cell (xls only)
#         Specifies the bottom-right cell in the range of data to import.
#
#     start_line (csv only)
#         The line to start reading from.
#
#     delimiter (csv only) (optional)
#         The delimiter that separates the columns in a delimited file. Defaults
#         to ",". Also accepts the special delimiter "whitespace", which uses
#         any whitespace between values as the delimiter (i.e. a mixture of tabs
#         and spaces, or a varying number of spaces) -- note that this does not
#         work if values contain spaces that are part of the data.
#
#     destination_table (optional)
#         The name of the table to import into. This switches the mode of import
#         from a single table using the data import name to a table with a user-
#         defined name that multiple import tasks can append to.
#
#     import_title_column (optional)
#         Used along with the destination_table option, this adds a column with
#         a user-defined name that holds the name of each data import task to
#         identify the rows that each individual task contributed to a common
#         table.
###
    [[orders]]
    order      = 1
    file       = sample.xls
    start_cell = D6
    end_cell   = F9
    
    [[office_supplies]]
    order      = 2
    file       = sample.xls
    worksheet  = Sheet2
    start_cell = I8
    end_cell   = J10
    columns    = item, color
    
    [[foo]]
    order      = 3
    file       = sample.xls
    worksheet  = Sheet3
    
    [[open_ended_foo]]
    order      = 4
    file       = sample.xls
    worksheet  = Sheet3
    start_cell = D14
    columns    = whee, blah
    
    [[csv_test]]
    order      = 5
    file       = sample.csv
    start_line = 1
    columns    = col1, col2
    delimiter  = ","

    [[csv_float_test]]
    order      = 6
    file       = sample_floats.csv
    types      = float, float, float
    delimiter  = whitespace
    
    [[null_placeholders]]
    order       = 7
    file        = sample.xls
    worksheet   = Sheet4
    start_cell  = C22
    end_cell    = D25
    null_values = -,
    db_null     = -1

    [[open_end_row_null_placeholders]]
    order       = 7
    file        = sample.xls
    worksheet   = Sheet4
    start_cell  = C22
    end_cell    = D
    null_values = -,
    db_null     = -1
    
    [[composite_import_part1]]
    order             = 8
    file              = sample.xls
    worksheet         = Sheet2
    columns           = item, color
    start_cell        = I8
    end_cell          = J8
    destination_table = composite_import

    [[composite_import_part2]]
    order             = 9
    file              = sample.xls
    worksheet         = Sheet2
    columns           = item, color
    start_cell        = I9
    end_cell          = J9
    destination_table = composite_import

    [[identifying_composite_import_part1]]
    order               = 10
    file                = sample.csv
    columns             = lhs, rhs
    destination_table   = identifying_composite_import
    import_title_column = import_step

    [[identifying_composite_import_part2]]
    order               = 11
    file                = sample2.csv
    worksheet           = Sheet2
    columns             = lhs, rhs
    destination_table   = identifying_composite_import
    import_title_column = import_step

    [[xlsx_test]]
    order = 12
    file  = xlsx_test.xlsx
    
    [[mdb_test_1]]
    order = 13
    file  = mdb_test.mdb
    table = mdb_import_test_1
    
    [[mdb_accdb_identifying_composite_1]]
    order               = 14
    file                = mdb_test.mdb
    table               = mdb_import_test_1
    destination_table   = mdb_import_test_2
    import_title_column = import_step
    
    [[mdb_accdb_identifying_composite_2]]
    order               = 15
    file                = accdb_test.accdb
    table               = accdb_import_test_1
    destination_table   = mdb_import_test_2
    import_title_column = import_step

[queries]
###
# The query runner is designed to run a set of queries against a number of
# databases with the same schema. Queries run in a specified order, and each
# query must be stored in its own file. Entries in the queries section may be
# added or removed freely.
#
# Queries may include a number of optional features in a special nested
# 'features' section underneath the query. Optional features include:
#
# 1. Named parameters using Oracle-style notation.
#    For example, for a file named emp_by_salary.sql containing the query:
#        SELECT * FROM employees e WHERE e.salary > :minimum_salary
#
#    The corresponding configuration would read:
#        [[Find employees by salary]]
#        order = 0
#        sql   = ..\sql\emp_by_salary.sql
#
#            [[[features]]]
#
#                [[[[named_parameters]]]]
#                minimum_salary = 50000
#
# 2. Named parameters using Oracle-style notation where the query is executed
#    once for each set of values in a collection.
#    For example, for a file named emp_by_salary_range.sql containing the query:
#       SELECT ':min - :max' AS range, e.name FROM employees e
#       WHERE e.salary BETWEEN :min AND :max
#
#    The corresponding configuration could read:
#        [[Find employees by salary grouping]]
#        order = 1
#        sql   = ..\sql\emp_by_salary_range.sql
#
#           [[[features]]]
#
#               [[[[multi_named_parameters]]]]
#               keys = min, max
#               value_sets = """[\
#                   [0, 35000], \
#                   [35001, 60000], \
#                   [60001, 1000000], \
#               ]"""
#
# 3. Named parameters using Oracle-style notation using different values on
#    a database-by-database basis. Database names must match the names in the
#    [databases] configuration section.
#    For example, for a file named inv_by_area.sql containing the query:
#        SELECT * FROM tblinventory i WHERE i.area > :min_area
#
#    The corresponding configuration would read:
#        [[Select inventory by minimum area]]
#        order = 2
#        sql   = r:\queries\inv_by_area.sql
#
#            [[[features]]]
#
#                [[[[database_named_parameters]]]]
#
#                    [[[[[Alberta]]]]]
#                    min_area = 100
#                    
#                    [[[[[BCCoast]]]]]
#                    min_area = 100
#
# 4. Templated queries using Python's string substitution. These are queries
#    which require some logic to dynamically generate part of the SQL, as
#    when certain columns must be included in the SELECT statement which are
#    only known at runtime.
#
#    Generating the substitution strings is handled by a user-created Python
#    script which is passed a connection to the current working database. There
#    are no restrictions on what the script may contain, except that it must
#    include the following method as its entry point:
#        getStrings(db)
#    which must return a dictionary of string substitution keys to the string
#    values to replace them with.
#
#    For example, for a file named qrycset.sql containing the query:
#        SELECT %(classifierCols)s FROM qrycset_crosstab
#
#    And the substitution script qrycset_template_provider.py containing:
#        def getStrings(projectDB):
#            sql = "SELECT classifierId FROM tblClassifiers"
#            results = projectDB.query(sql)
#            classifiers = [row.classifierId for row in results]
#
#            stringSubs = {
#                "classifierCols": ", ".join(
#                    ["qryCSet_CrossTab.[%(classifier)s] AS [cls_%(classifier)s]"
#                     % {"classifier": classifier} for classifier in classifiers])}
#
#            return stringSubs
#
#    The corresponding configuration would read:
#        [[Select classifiers]]
#        order = 3
#        sql   = ..\sql\qrycset.sql
#    
#            [[[features]]]
#
#                [[[[templated]]]]
#                template_provider = r:\scripts\qrycset_template_provider.py
#
# 5. Reporting queries. These are ordinary SELECT statements which the
#    QueryRunner application runs against each configured database, then appends
#    the output to a specified database and table. The output table can be
#    initially dropped by setting the overwrite_reporting_tables flag in the
#    [DEFAULT] section at the top of this file.
#    
#    Note that the query must always return the same columns in the same order
#    for the results to be appended together, so this feature is incompatible
#    with the "templated queries" feature in cases where the columns in the
#    SELECT statement are dynamic.
#
#    The name of the current database can be included in an automatically
#    generated column in the output table by setting the db_title_column to the
#    name of a column to store the current database's title in.
#
#    For example, for a file named simple_inv_by_area.sql containing the query:
#        SELECT * FROM tblinventory i WHERE i.area > 10000
#
#    The corresponding configuration would read:
#        [[Simplified select inventory by minimum area]]
#        order = 4
#        sql   = r:\queries\simple_inv_by_area.sql
#
#            [[[features]]]
#
#                [[[[reporting]]]]
#                output_database  = $output_path\Reports.mdb
#                output_table     = inventory_area
#                db_title_column  = db_title
#
#    Reporting queries can also be written to Excel spreadsheets with these
#    options under the [[[[reporting]]]] heading:
#        file      = <name>.xlsx
#        template  = <template>.xlsx
#        worksheet = <worksheet to insert into>
#        cell      = <top-left cell to begin inserting query results at>
#
#    Output to a PowerPoint template (pptx format) is also supported. This
#    feature copies the template to the specified output file path and fills in
#    the specified shape's text box with the query result. Queries must return a
#    single row with a single column of data.
#        file     = <output file name>.pptx
#        template = <template file name>.pptx
#        slide    = <slide number, starting from 1>
#        shape    = <the name of the shape to write the query result to>
###
    [[Inventory Area by Classifiers]]
    order = 1
    sql   = sql\inventory_area_by_classifiers.sql

        [[[features]]]

            [[[[templated]]]]
            template_provider = sql\template_providers\inventory_area_by_classifiers_template_provider.py
            
            [[[[database_named_parameters]]]]

                [[[[[Alberta_half]]]]]
                min_inventory_area = 100
                
            [[[[reporting]]]]
            output_database = $output_path\reports\Reports.mdb
            output_table    = inventory_area_by_classifiers
            db_title_column = db_title

    [[Classifiers to Excel]]
    order = 2
    sql   = sql\select_all.sql
    
        [[[features]]]
        
            [[[[named_parameters]]]]
            table = tblclassifiers
            
            [[[[reporting]]]]
            file      = $output_path\reports\Reports.xlsx
            worksheet = classifiers

    [[Classifiers to Excel with template]]
    order = 3
    sql   = sql\select_all.sql
    
        [[[features]]]
        
            [[[[named_parameters]]]]
            table = tblclassifiers
            
            [[[[reporting]]]]
            file      = $output_path\reports\Templated_Reports.xlsx
            template  = template.xlsx
            worksheet = classifiers
            cell      = A5

    [[Test data to PowerPoint template - shape 1 of 2]]
    order = 4
    sql   = sql\ppt_shape_1_data.sql
    
        [[[features]]]
        
            [[[[reporting]]]]
            file     = $output_path\reports\PowerPoint_Report.pptx
            template = template.pptx
            slide    = 1
            shape    = Rectangle 4
    
    [[Test data to PowerPoint template - shape 2 of 2]]
    order = 5
    sql   = sql\ppt_shape_2_data.sql
    
        [[[features]]]
        
            [[[[reporting]]]]
            file     = $output_path\reports\PowerPoint_Report.pptx
            template = template.pptx
            slide    = 1
            shape    = Oval 5
